# BrankoLlama

**Note:** This project is currently in progress. Full installation instructions and additional details will be provided soon.

## Overview

BrankoLlama is my local LLM with Retrieval-Augmented Generation (RAG) and fine-tuning project. This mono repo consists of both frontend and backend components designed to help others set up and interact with their own LLM with RAG and fine-tuning capabilities. Intended for use with llama.cpp and .gguf models. My personal choice at the moment is Qwen2 7b Instruct (https://huggingface.co/Qwen/Qwen2-7B-Instruct-GGUF/tree/main)

## Table of Contents
1. [Features](#features)
2. [Technologies](#technologies)
3. [Installation](#installation)
4. [Usage](#usage)
5. [Contributing](#contributing)
6. [License](#license)

## Features

### Frontend

- **Chat with Your Model:** Engage in conversations with your LLM.
- **Toggle RAG:** Enable or disable Retrieval-Augmented Generation during chats.
- **Upload Documents:** Upload documents to be embedded and saved to the database.
- **View Documents:** Access and view documents stored in the database.

### Backend

- **Fine-Tuning Models:** Fine-tune your own models for better performance and customization.

## Technologies

### Frontend

- **JavaScript**
- **React**
- **Tailwind CSS**
- **shadcn**

### Backend

- **Python**
- **Django**
- **llama.cpp** (Requires separate installation)
- **Docker containers for Weaviate**
- **Weaviate vector database**

## Installation

*Instructions coming soon...*

## Usage

*Instructions coming soon...*

## Contributing

I welcome contributions! I am working on my contributing.md file, but in the meantime, please send me a message if you have any recommendations!

## License

This project is licensed under the MIT License.